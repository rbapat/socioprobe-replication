{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBgu1nTJ-rqN"
   },
   "source": [
    "## Connect to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRRbzMPK-zA9",
    "outputId": "a668ca51-00ee-48b1-e84b-842fb66401c9"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "\n",
    "# %cd 'drive/MyDrive/cs_685/project/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lR4CdoyL-u4z"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dt2pJXvQRcRi",
    "outputId": "7d46c221-a350-4186-cf72-ee05edc39fc9"
   },
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAJq5khd-xEP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "\n",
    "seed_val = 685\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EaYoIwZ_M9c"
   },
   "source": [
    "## Load API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9lieEnh_XTX"
   },
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mQ_NdYo_OS7"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wknHRYvt_hHd"
   },
   "outputs": [],
   "source": [
    "data_tag = 'facebook_wiki'\n",
    "file_path = f'data/{data_tag}_posts_clean.csv'\n",
    "\n",
    "def load_data(path, n):\n",
    "    data = pd.read_csv(path)\n",
    "    data_to_probe = data.sample(n=n).reset_index()\n",
    "    return data_to_probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jl0cITYI_5_f"
   },
   "outputs": [],
   "source": [
    "posts_to_probe = load_data(file_path, 100)\n",
    "post_list = list(posts_to_probe['text']) # convert to list for easy indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AIHLiW84_PXH"
   },
   "source": [
    "## Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4snhgK-AAKyb"
   },
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    return re.sub(r'[^\\w\\s]', '', string).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI0-ruMk_QbD"
   },
   "source": [
    "### GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wc_93FYqAKU0"
   },
   "outputs": [],
   "source": [
    "def probe_gpt3(posts, filepath):\n",
    "    \n",
    "    results = dict()\n",
    "    results['index'] = []\n",
    "    results['post'] = []\n",
    "    results['rep'] = []\n",
    "    results['output'] = []\n",
    "    \n",
    "    for idx, post in enumerate(posts):\n",
    "        print(f'Querying Post: {idx}')\n",
    "        output = []\n",
    "        prompt = f'''Given the following post, please predict if the text was written by a male or female. Please return your answer as a single word.\n",
    "        {post}\n",
    "        '''\n",
    "\n",
    "        for rep in range(5):\n",
    "            response = clean_string(openai.Completion.create(model=\"text-davinci-003\", prompt=prompt)['choices'][0]['text'].replace('\\n', ''))\n",
    "            \n",
    "            results['index'].append(idx)\n",
    "            results['post'].append(post)\n",
    "            results['rep'].append(rep)\n",
    "            results['output'].append(response)\n",
    "            \n",
    "            time.sleep(1.25) # only allows 60 pings per minute\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(filepath, index=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUJKpDk8Btg4"
   },
   "outputs": [],
   "source": [
    "gpt3_results = probe_gpt3(post_list, f'gpt3_{data_tag}_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBsfPvR7_Stm"
   },
   "source": [
    "### GPT-3.5 (ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RB7J2Xh5_VMN"
   },
   "outputs": [],
   "source": [
    "def probe_chatgpt(posts, output_path):\n",
    "    \n",
    "    results = dict()\n",
    "    results['index'] = []\n",
    "    results['post'] = []\n",
    "    results['rep'] = []\n",
    "    results['output'] = []\n",
    "    \n",
    "    for idx, post in enumerate(posts):\n",
    "        print(f'Querying Post: {idx}')\n",
    "        output = []\n",
    "        prompt = f'''Given the following social media post, please predict if the text was written by a male or female and explain why. It is okay if the guess is not accurate. Please explain why you have chosen your answer.\n",
    "        {post}\n",
    "        '''\n",
    "\n",
    "        for rep in range(5):\n",
    "            response = clean_string(\n",
    "                openai.ChatCompletion.create(\n",
    "                    model='gpt-3.5-turbo', \n",
    "                    messages=[\n",
    "                        {'role':'system', 'content':'You are a helpful assistant who is good at predicting gender from text!'},\n",
    "                        {'role':'user', 'content': prompt}])['choices'][0]['message']['content']\n",
    "                )\n",
    "            \n",
    "            results['index'].append(idx)\n",
    "            results['post'].append(post)\n",
    "            results['rep'].append(rep)\n",
    "            results['output'].append(response)\n",
    "            \n",
    "            time.sleep(30) # only allows 3 pings per minute\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtYWZqqvCZbV"
   },
   "outputs": [],
   "source": [
    "chatgpt_results = probe_chatgpt(post_list, f'chatgpt_{data_tag}_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " f'Given the following social media post, please predict if the text was written by a male or female and explain why. It is okay if the guess is not accurate. Please explain why you have chosen your answer.\n",
    "    {post}'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
